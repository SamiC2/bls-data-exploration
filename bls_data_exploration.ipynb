{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing : steps to flow: \n",
    "- Select Relevant Columns - Only keep the important columns for your analysis.\n",
    "- Handle Missing Values - Either drop or fill missing data.\n",
    "- Remove Duplicates - Remove duplicate rows from the dataset.\n",
    "- Validate Data Types - Ensure numeric columns are properly formatted.\n",
    "- Review Data Consistency - Check for consistency in categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data using pandas\n",
    "bls_data=pd.read_excel(\"./Ressources/all_data_M_2023.xlsx\")\n",
    "# Preview the first few rows to check if the data is being read correctly\n",
    "bls_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bls_data.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the columns names\n",
    "bls_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> For your BLS data, the most relevant columns to keep depend on your project's focus, but based on analyzing high-paying jobs and employment trends, these would likely be the most useful:\n",
    "\n",
    "- AREA and AREA_TITLE: To identify the geographic region and perform location-based analysis.\n",
    "- NAICS and NAICS_TITLE: For industry classification, which helps analyze trends by industry sector.\n",
    "- OCC_CODE and OCC_TITLE: For occupation-specific analysis, which is crucial when looking at job types and wages.\n",
    "- TOT_EMP: Total employment helps in analyzing job concentration and demand.\n",
    "- H_MEAN and A_MEAN: Hourly and annual mean wages are essential for identifying high-paying jobs.\n",
    "- H_MEDIAN and A_MEDIAN: Median wages to assess typical earnings in each role.\n",
    "- H_PCT75 and A_PCT75, H_PCT90 and A_PCT90: These percentile columns help in understanding wage distribution at higher levels, useful for identifying the top earners."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SELECT THE RELEVANT COLUMNS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " >the columns to keep:\n",
    "* OCC_CODE and OCC_TITLE: For analyzing specific occupations and job categories.\n",
    "* NAICS and NAICS_TITLE: If you're looking to correlate job salaries with specific industries.\n",
    "* AREA and AREA_TITLE: If you're interested in geographic variations, such as comparing salaries across regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the relevant columns from your DataFrame\n",
    "relevant_columns = [\n",
    "    'AREA', 'AREA_TITLE', 'NAICS', 'NAICS_TITLE', \n",
    "    'OCC_CODE', 'OCC_TITLE', 'TOT_EMP', 'PRIM_STATE',\n",
    "    'H_MEAN', 'A_MEAN', 'H_MEDIAN', 'A_MEDIAN',\n",
    "    'H_PCT75', 'A_PCT75', 'H_PCT90', 'A_PCT90'\n",
    "]\n",
    "\n",
    "# Subset the DataFrame\n",
    "bls_df_clean = bls_data[relevant_columns]\n",
    "bls_df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique values for each column in the DataFrame\n",
    "unique_values = bls_df_clean.apply(lambda x: x.unique())\n",
    "\n",
    "# Display the unique values for each column\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace multiple specific special characters with NaN\n",
    "bls_df_clean.replace({'#': np.nan, '*': np.nan, '@': np.nan, '$': np.nan}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handel missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in the selected columns\n",
    "missing_values = bls_df_clean.isnull().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bls_df_clean= bls_df_clean.dropna(how='any')\n",
    "# bls_df_clean.info()\n",
    "# check if we do have some duplicated valuesto be dorped \n",
    "# bls_df_clean.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate rows if any\n",
    "# bls_df_clean=bls_df_clean.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display a the first five row of my data \n",
    "bls_df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check summary statistics of the cleaned dataset\n",
    "bls_df_clean.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bls_df_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by AREA and calculate mean for each numeric column\n",
    "area_summary = bls_df_clean.groupby('AREA').agg({\n",
    "    'H_MEAN': 'mean',\n",
    "    'A_MEAN': 'mean',\n",
    "    'H_MEDIAN': 'mean',\n",
    "    'A_MEDIAN': 'mean',\n",
    "    'H_PCT75': 'mean',\n",
    "    'A_PCT75': 'mean',\n",
    "    'H_PCT90': 'mean',\n",
    "    'A_PCT90': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Display summary statistics for each area\n",
    "area_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter dataset to include only rows where the annual mean wage (A_MEAN) or hourly wage (H_MEAN) exceeds the equivalent of $100K per year.\n",
    "filtred_bls_df = bls_df_clean[(bls_df_clean['A_MEAN'] >= 100000) | (bls_df_clean['H_MEAN'] >= 48.08)]\n",
    "filtred_bls_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify Consistency: Ensure that all columns have consistent formatting and correct data types.\n",
    "filtred_bls_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # convert the total employment  to a numeric to ensure consistency\n",
    "filtred_bls_df['TOT_EMP'] = pd.to_numeric(filtred_bls_df['TOT_EMP'], errors='coerce')\n",
    "filtred_bls_df['OCC_CODE'] = pd.to_numeric(filtred_bls_df['OCC_CODE'], errors='coerce')\n",
    "\n",
    "# recheck for a null values\n",
    "filtred_bls_df['TOT_EMP'].isna().sum()\n",
    "filtred_bls_df=filtred_bls_df.dropna(how='any')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that AREA_TITLE, NAICS, NAICS_TITLE, OCC_CODE, and OCC_TITLE have consistent formatting (e.g., no\n",
    "#  leading/trailing spaces, all uppercase/lowercase where necessary)\n",
    "\n",
    "#str.strip to Remove leading/trailing spaces and str.title to standardize case\n",
    "filtred_bls_df['AREA_TITLE'] = filtred_bls_df['AREA_TITLE'].str.strip().str.title()#strip spaces and standardize text formatting \n",
    "filtred_bls_df['OCC_TITLE'] = filtred_bls_df['OCC_TITLE'].str.strip().str.title()\n",
    "filtred_bls_df['NAICS_TITLE'] = filtred_bls_df['NAICS_TITLE'].str.strip()\n",
    "\n",
    "filtred_bls_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtred_bls_df = filtred_bls_df.loc[filtred_bls_df['OCC_CODE'].str.contains('-', na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datafinal check\n",
    "# filtred_bls_df.head()\n",
    "display(filtred_bls_df.tail(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oews_data = pd.read_csv(\"./Ressources/educational_attainment.csv\",delimiter=';')\n",
    "# oews_data.head()\n",
    "# oews_data.columns\n",
    "Educ_data = pd.read_csv(\"./Ressources/usa_00006.csv\",delimiter=',')\n",
    "# Educ_data.columns\n",
    "Educ_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Educ_data.columns\n",
    "# Educ_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Educ_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values_2 = Educ_data.apply(lambda x: x.unique())\n",
    "unique_values_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_c = ['REGION','STATEICP' ,'IND','OCCSOC', 'INCTOT', 'INCWAGE', 'EDUC', 'EDUCD', 'SEX', 'AGE']\n",
    "filtred_owes_df=Educ_data[relevant_c]\n",
    "filtred_owes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtred_owes_df=filtred_owes_df.duplicated()\n",
    "filtred_owes_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtred_owes_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtred_owes_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtred_owes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(filtred_bls_df.head(2))\n",
    "display(filtred_bls_df.tail(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(filtred_owes_df.tail())\n",
    "display(filtred_owes_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtred_owes_df['OCCSOC'] = filtred_owes_df['OCCSOC'].str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtred_owes_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_df = pd.merge(filtred_bls_df,filtred_owes_df,on=['OCC_CODE', how= 'inner'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
